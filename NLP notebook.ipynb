{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ux0qZNQD8N-q"
   },
   "source": [
    "# **NLP** FISAC-2---NLTK Taggers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHXPETEB8gtK"
   },
   "source": [
    "### Name-Utkarsh Aggarwal\n",
    "### Registration number-200968234\n",
    "### Section-'A'\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybQD3Bcz9PgK"
   },
   "source": [
    "#### Assignment:-\n",
    "\n",
    "Create a regular expression tagger and various unigram and n-gram taggers, incorporating backoff, and train them on part of the Brown Corpus. \n",
    "a. Create three different combinations of the taggers. Test the accuracy of each combined tagger. Which combination works best? \n",
    "b. Try varying the size of the training corpus. How does it affect your results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "GmWcyiJZ7hHF"
   },
   "outputs": [],
   "source": [
    "## Importing nltk and downloading brown corpus.\n",
    "import nltk\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dHmIqOmR9y-R",
    "outputId": "eab02cc1-da14-4bf6-dbeb-f887ec41d2ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\utkar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9z2ZVrC95VQ",
    "outputId": "358ed61d-5f33-4d1d-cbcf-271bbe432c73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the various categories present in the Brown Corpus\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "epau9OTk-CNY",
    "outputId": "b8d1e241-0a50-423d-e33b-3401159597c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('In', 'IN'), ('American', 'JJ'), ('romance', 'NN'), (',', ','), ('almost', 'RB'), ('nothing', 'PN'), ('rates', 'VBZ'), ('higher', 'RBR'), ('than', 'CS'), ('what', 'WDT'), ('the', 'AT'), ('movie', 'NN'), ('men', 'NNS'), ('have', 'HV'), ('called', 'VBN'), ('``', '``'), ('meeting', 'VBG'), ('cute', 'JJ'), (\"''\", \"''\"), ('--', '--'), ('that', 'DT'), ('is', 'BEZ'), (',', ','), ('boy-meets-girl', 'NN'), ('seems', 'VBZ'), ('more', 'QL'), ('adorable', 'JJ'), ('if', 'CS'), ('it', 'PPS'), (\"doesn't\", 'DOZ*'), ('take', 'VB'), ('place', 'NN'), ('in', 'IN'), ('an', 'AT'), ('atmosphere', 'NN'), ('of', 'IN'), ('correct', 'JJ'), ('and', 'CC'), ('acute', 'JJ'), ('boredom', 'NN'), ('.', '.')], [('Just', 'QL'), ('about', 'RB'), ('the', 'AT'), ('most', 'QL'), ('enthralling', 'JJ'), ('real-life', 'NN'), ('example', 'NN'), ('of', 'IN'), ('meeting', 'VBG'), ('cute', 'JJ'), ('is', 'BEZ'), ('the', 'AT'), ('Charles', 'NP'), ('MacArthur-Helen', 'NP'), ('Hayes', 'NP'), ('saga', 'NN'), (':', ':'), ('reputedly', 'RB'), ('all', 'ABN'), ('he', 'PPS'), ('did', 'DOD'), ('was', 'BEDZ'), ('give', 'VB'), ('her', 'PPO'), ('a', 'AT'), ('handful', 'NN'), ('of', 'IN'), ('peanuts', 'NNS'), (',', ','), ('but', 'CC'), ('he', 'PPS'), ('said', 'VBD'), ('simultaneously', 'RB'), (',', ','), ('``', '``'), ('I', 'PPSS'), ('wish', 'VB'), ('they', 'PPSS'), ('were', 'BED'), ('emeralds', 'NNS'), (\"''\", \"''\"), ('.', '.')], ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve tagged sentences in the lore category\n",
    "#getting the data ready\n",
    "lore1 = brown.tagged_sents(categories='lore')\n",
    "lore1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwKRCD4__RE7",
    "outputId": "e10d4bb3-d30b-4e11-a911-045abb7b8b14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4881"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of the selected part of the corpus\n",
    "len(lore1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogjoRkSWCr4Z"
   },
   "source": [
    "## creating a regular expression tagger:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "uwjYCSCuCods"
   },
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    (r'.*', 'NN'),                     # nouns\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),   # cardinal numbers\n",
    "    (r'(The|the|A|a|An|an)$', 'AT'),   # articles\n",
    "    (r'.*able$', 'JJ'),                # adjectives\n",
    "    (r'.*s$', 'NNS'),                  # plural nouns\n",
    "    (r'.*\\'s$', 'NN$'),                # possessive nouns\n",
    "    (r'.*ing$', 'VBG'),                # gerunds\n",
    "    (r'.*ed$', 'VBD'),                 # past tense verbs\n",
    "    (r'.*es$', 'VBZ'),                 # 3rd singular present\n",
    "    (r'.*ness$', 'NN'),                # nouns formed from adjectives\n",
    "    (r'.*ly$', 'RB'),                  # adverbs\n",
    "    (r'.*ould$', 'MD')                 # modals\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "4HRU1uKnA2aj"
   },
   "outputs": [],
   "source": [
    "# splitting into a train and test set (95% train, 5% test)\n",
    "train = int(len(lore1) * 0.95)\n",
    "train_sents = lore1[:train]\n",
    "test_sents = lore1[train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4SPlCm_Df7R",
    "outputId": "1823849f-6c79-4b4a-f1d6-dea0f43dfde6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12641631595985756"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline accuracy (without backoff)\n",
    "t0 = nltk.RegexpTagger(patterns)\n",
    "t0.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sg5uXu-VD-mO"
   },
   "source": [
    "# Test various combination of taggers with backoff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJL4juXUDr9r",
    "outputId": "b93fbd63-6653-4725-a205-e3fe5a31059a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8648429912593072"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regexp + unigram\n",
    "t0 = nltk.RegexpTagger(patterns)\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t1.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmRBU6KuELrv",
    "outputId": "f8fdcc38-4d7b-40f4-eed2-f2cfdaef5ea5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5809323405632891"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigram + unigram\n",
    "t0 = nltk.BigramTagger(train_sents)\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t1.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YnxCNUdAEO2k",
    "outputId": "db91e166-3e81-4d7f-ff2e-e211ec37ae22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8709938491421172"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regexp + unigram + bigram\n",
    "t0 = nltk.RegexpTagger(patterns)\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "t2.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-MGlLn6ERwb",
    "outputId": "2d324eaa-de65-40e6-9e99-9a539f876767"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8727743606345095"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regexp + unigram + bigram + trigram\n",
    "t0 = nltk.RegexpTagger(patterns)\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "t3 = nltk.TrigramTagger(train_sents, backoff=t2)\n",
    "t3.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7593072191647783"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regexp + bigram + trigram\n",
    "t0 = nltk.RegexpTagger(patterns)\n",
    "t1 = nltk.BigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.TrigramTagger(train_sents, backoff=t1)\n",
    "t2.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nA1DAIobEVEs",
    "outputId": "ed6d6173-71ae-4442-f543-bd95f1e3126e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8692133376497249"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regexp + unigram + trigram\n",
    "t0 = nltk.RegexpTagger(patterns)\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.TrigramTagger(train_sents, backoff=t1)\n",
    "t2.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEicKnD7Eio4"
   },
   "source": [
    "The highest accuracy is obtained on the combination with regexp + unigram + bigram + trigram which is 0.8727743606345095.<br>\n",
    "\n",
    "The best combination has the simplest tagger (i.e, regexp) as the last backoff, and the most specific tagger (i.e, unigram/bigram/trigram) as the first to tag the sentences.<br>\n",
    "\n",
    "The second highest is obtained on the combination with regexp + unigram + bigram which is 0.8709938491421172.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zM_eq0BSFfuv"
   },
   "source": [
    "# b. Try varying the size of the training corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lt73wYvmF-Pj"
   },
   "source": [
    "## Trying with a smaller training set:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GoVCAvChF9bZ",
    "outputId": "6afb286f-429f-4eef-abb1-f8301c9a1e1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1716"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "religion = brown.tagged_sents(categories='religion')\n",
    "len(religion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qYY3UjgVFezC"
   },
   "outputs": [],
   "source": [
    "# splitting into a train and test set (95% train, 5% test)\n",
    "train = int(len(religion) * 0.95)\n",
    "train_sents = religion[:train]\n",
    "test_sents = religion[train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cf8xp_7iI1xG",
    "outputId": "35c67793-5caf-40a2-80f9-36dccb873f01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8327053504144687"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second best accuracy\n",
    "# regexp + unigram + bigram\n",
    "t0 = nltk.RegexpTagger(patterns)\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "t2.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jXXLGkQ2EYRE",
    "outputId": "59e005f9-c096-4fc5-a310-185f4d87a284"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8342125094197438"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best accuracy\n",
    "# regexp + unigram + bigram + trigram\n",
    "t0 = nltk.RegexpTagger(patterns)\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "t3 = nltk.TrigramTagger(train_sents, backoff=t2)\n",
    "t3.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1F8qbJiBGzfR"
   },
   "source": [
    "The accuracy is slightly lower on a smaller training set but the difference is not huge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luKlwODUHP5Z"
   },
   "source": [
    "## Trying with a larger training set.<br>\n",
    "(taking full Brown Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyVoNldoHPA-",
    "outputId": "f034cb03-3ceb-48ca-ef30-4ad725c65943"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57340"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_corpus = brown.tagged_sents()\n",
    "len(B_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "EBuINLP8GgYr"
   },
   "outputs": [],
   "source": [
    "# splitting into a train and test set (95% train, 5% test)\n",
    "train = int(len(B_corpus) * 0.95)\n",
    "train_sents = B_corpus[:train]\n",
    "test_sents = B_corpus[train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TniZiH2iJFCu",
    "outputId": "eb3faab0-b5bc-4ef6-9c47-8b61754c76c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9118542275243601"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#second best accuracy.\n",
    "# regexp + unigram + bigram\n",
    "t0 = nltk.RegexpTagger(patterns)\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "t2.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EDxfQj3HxD-",
    "outputId": "bf42626e-cb17-4112-c067-3562bd48cb93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9123649214552735"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best accuracy.\n",
    "# regexp + unigram + bigram + trigram\n",
    "t0 = nltk.RegexpTagger(patterns)\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "t3 = nltk.TrigramTagger(train_sents, backoff=t2)\n",
    "t3.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "najXdJpuIElP"
   },
   "source": [
    "## The accuracy increases when trained on much larger corpus.\n",
    "<br>\n",
    "------------------------------------------------------------------------------------------\n",
    "------------------------------------------------------------------------------------\n",
    "\n",
    "##Clearly,we can observe that the accuracy is directly proportional to the size of corpus used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r43xIE6KHzwc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
